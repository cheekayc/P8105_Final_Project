---
title: "Tests & Analysis"
output: github_document
date: "2022-12-05"
author: "Jiayi Yang, Chee-Kay Cheong"
---

```{r setup}
knitr::opts_chunk$set(message = FALSE)

library(tidyverse)
library(lubridate)
library(plotly)
library(mgcv)
library(moments)
library(modelr)
```

Data input and cleaning 
```{r}
bakery_df =
  read_csv("./Data/Bakery_sales.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    unit_price = str_replace(unit_price, "â‚¬", ""),
    unit_price = str_replace(unit_price, ",", "."),
    unit_price = as.numeric(unit_price),
    product_name = article, 
    rev = quantity * unit_price
    ) %>% 
  filter(product_name != ".") %>% 
  select(-article)

bakery_df
```

### ANOVA

ANOVA tests whether there is a difference in means of the groups at each level (each individual month) of the independent variable.

One way anova test can test if the mean sales of quarter 1 (Jan - Mar) is different from the mean sales of quarter 3 (Jun - Aug).

The null hypothesis is that there is no difference in the mean sales of 1st quarter and 3rd quarter.                                        
The alternative hypothesis is that the means are different from one another.

```{r ANOVA}
anova_df =
  bakery_df %>% 
  mutate(
    year = year(date),
    month = month(date)
    ) 
  

third_sales = 
  anova_df %>% 
  filter((month == 6)|(month == 7)|(month == 8)) %>% 
  group_by(year, month) %>% 
  summarize(third_sales = n()) %>% 
  group_by(year, month) %>% 
  mutate(ID = cur_group_id())
  
first_sales = 
  anova_df %>% 
  filter((month == 1) |(month == 2)|(month == 3)) %>% 
  group_by(year, month) %>% 
  summarize(first_sales = n()) %>% 
  group_by(year, month) %>% 
  mutate(ID = cur_group_id())
  
anova_test_df = 
  left_join(third_sales, first_sales, by = c("ID"))

anova_test_df

one.way <- aov(first_sales ~ third_sales, data = anova_test_df)

summary(one.way)
```
The ANOVA test p-value is 0.00451 which is less than alpha level of 0.05, so we reject the null hypothesis and conclude that the mean sales in quarter 1 is statistically significantly different from the mean sales of quarter 3.
 
### Simple Linear Regression for croissant and test the model using Cross Validation
```{r}
croissant_df = 
  bakery_df %>% 
  filter(str_detect(product_name, "CROISSANT")) %>% 
  mutate(
    month = month(date),
    qty_cp = (quantity > 5) * (quantity - 5)
    )

ggplot(croissant_df, aes(x = quantity, y = rev)) +
  geom_point()

croissant_reg = lm(rev ~ quantity, croissant_df)

croissant_reg %>% 
  broom::tidy()
```
Examine cross validation of this simple linear regression model
```{r}
linear_mod = lm(rev ~ quantity, croissant_df)
pwl_mod    = lm(rev ~ quantity + qty_cp, data = croissant_df)
smooth_mod = gam(rev ~ s(quantity), data = croissant_df)
```

```{r}
croissant_df %>% 
  gather_predictions(linear_mod, pwl_mod, smooth_mod) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = quantity, y = rev)) + 
  geom_point(alpha = .5) +
  geom_line(aes(y = pred), color = "red") + 
  facet_grid(~model)
```
The three models are very similar.

Re-sample the dataset by `crossv_mc` and let's see the rmse of each model
```{r}
set.seed(2022)
cv_df =
  crossv_mc(croissant_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(
    linear_mod  = map(train, ~lm(rev ~ quantity, data = .x)),
    pwl_mod     = map(train, ~lm(rev ~ quantity + qty_cp, data = .x)),
    smooth_mod  = map(train, ~gam(rev ~ s(quantity), data = as_tibble(.x)))) %>% 
  mutate(
    rmse_linear = map2_dbl(linear_mod, test, ~rmse(model = .x, data = .y)),
    rmse_pwl    = map2_dbl(pwl_mod, test, ~rmse(model = .x, data = .y)),
    rmse_smooth = map2_dbl(smooth_mod, test, ~rmse(model = .x, data = .y)))

```
Then plot the rmse graph
```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```
Based on the results, there is a slightly improvement using piecewise linear model as it has a lower tail of rmse on the top. Since there are no significant difference between the three model including the non-linear smooth model, we can conclude that the basic linear model is clear enough to be accounted for this relationship in the product of croissant.

### Multiple Linear Regression (test version)

We are interested in testing the relationship between the unit price of a product and its quantity being sold. Considering that 
the sales of bakery varies by month, so we included `month` in our model as a confounder to be controlled.

Linear Regression check assumption 
Linear Regression for baguette 
```{r}
baguette_df = 
  bakery_df %>% 
  filter(str_detect(product_name, "BAGUETTE")) %>% 
  mutate(
    month = month(date)
  )
baguette_reg = lm(rev ~ unit_price + quantity + month, baguette_df)

# Use backward elimination based on AIC to find a mlr model 
baguette_model_2 = step(baguette_reg, direction = "backward")
summary(baguette_model_2) %>% broom::tidy() %>% knitr::kable(digits = 3)
anova(baguette_model_2, baguette_reg)

baguette_reg %>% 
  broom::tidy()
```

Examine assumptions for the chosen Linear Regression model

```{r}
par(mfrow = c(2, 2))
plot(baguette_reg)
```




### One-sample T-test

##### Regular Baguette (Two-sided)

We are interested in testing if the mean price of **regular baguette** in this bakery is significantly different from 
the average price for a baguette in Paris, which is 1.07 euros. 

Null hypothesis: The mean price of baguette in this bakery is the same as the average price of baguette in Paris.

Alternative hypothesis: The mean price of baguette in this bakery is different from the average price of baguette in Paris.

```{r}
bakery_df %>% 
  filter(product_name == "TRADITIONAL BAGUETTE") %>% 
  group_by(date) %>% 
  summarize(total_sale = sum(quantity)) %>% 
  ggplot(aes(x = total_sale)) +
  geom_histogram()

baguette_onet = 
  bakery_df %>% 
  filter(product_name == "BAGUETTE") %>%
  select(unit_price)

baguette_t_results = 
  t.test(baguette_onet, mu = 1.07 , alternative = "two.sided") %>% 
  broom::tidy()
```

The p-value is much smaller than the alpha (0.05), so we would reject the null hypothesis. At 5% level of significance, we have sufficient 
evidence to conclude that the mean price of baguette in this bakery is significantly different from the average price of baguette in Paris.


##### Traditional Baguette (One-sided)

We noticed that the price of traditional baguette in this bakery is higher than the average price of traditional baguette in France. The
price of the traditional French loaf is around 0.90 Euros in bakeries. Therefore, we would like to conduct a one-sided T-test to see if the price difference is significant. 

Null hypothesis: The mean price of traditional baguette in this bakery is the same as the average price of traditional baguette in France.

Alternative hypothesis: The mean price of traditional baguette in this bakery is higher than the average price of traditional baguette in
France.

```{r}
bakery_df %>% 
  filter(product_name == "TRADITIONAL BAGUETTE") %>% 
  count(unit_price)
  
trad_baguette_onet = 
  bakery_df %>% 
  filter(product_name == "TRADITIONAL BAGUETTE") %>%
  select(unit_price)

trad_baguette_t_results = 
  t.test(trad_baguette_onet, mu = 0.90, alternative = "greater") %>% 
  broom::tidy()
```

The p-value is much smaller than the alpha (0.05), so we would reject the null hypothesis. At 5% level of significance, we have sufficient 
evidence to conclude that the mean price of traditional baguette in this bakery is significantly higher than the average price of baguette 
in Paris.


### Generalized Additive Model 

Find the *rush hours* of a typical day:
```{r}
bakery_df = 
  bakery_df %>% 
  mutate(
    Hour = hour(time),
    Month = month(date))

bakery_df %>% 
  group_by(Hour) %>% 
  count() %>% 
  ggplot(aes(x = Hour, y = n)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = seq(7, 20), limit = c(7, 20)) +
  scale_y_continuous(limit = c(0,50000)) +
  labs(
    title = "Peak hours",
    x = "Hour (24-hour format)",
    y = "Number of times appeared")
```

Overall, what hours has the most number of products sold?
```{r}
bakery_df %>% 
  mutate(year = year(date)) %>% 
  filter(year == 2021) %>% 
  group_by(Hour) %>% 
  summarize(
    n_sold = sum(quantity) / 365) %>% 
  ggplot(aes(x = Hour, y = n_sold)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = seq(7, 20), limit = c(7, 20)) +
  scale_y_continuous(limit = c(0,120)) +
  labs(
    title = "Peak hours",
    x = "Hour (24-hour format)",
    y = "Number of products sold")
```

```{r}
smooth_mod = gam(quantity ~ s(Hour) + s(Month), data = bakery_df)

smooth_mod %>% broom::tidy()
```


```{r}
bakery_df %>%
  mutate(
    month = month(date),
    year = year(date)) %>% 
  filter(month == 2 & year == 2021) %>% 
  group_by(product_name) %>% 
  summarize(total_sale = sum(quantity)) %>% 
  filter(total_sale < 1000) %>% 
  ggplot(aes(x = total_sale)) +
  geom_histogram(bins = 71)

skew = 
bakery_df %>% 
  group_by(date) %>% 
  summarize(total_sale = sum(quantity))

# Skewness test
print(skewness(skew))
```


